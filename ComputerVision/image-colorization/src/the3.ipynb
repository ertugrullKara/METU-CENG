{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import ConvNet\n",
    "import numpy as np\n",
    "from evaluate import main\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet(learning_rate=1e-3, first_kernel=48, \n",
    "                                first_kernel_size=11, second_kernel=48,\n",
    "                                second_kernel_size=3, \n",
    "                                last_kernel_size=1)\n",
    "net.load_model(\"models/bestmodel_48_11_48_3_1_0.001.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(net.train_data.shape, net.train_data_gt.shape)\n",
    "# print(net.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48 11 3 1\n",
      "0.30/1.00\n",
      "Epoch [1/500]  AvgTraining Loss: 0.0775\t\tEpoch [1/500]  AvgValidation Loss: 0.0220\tValidation loss improved.\n",
      "\n",
      "0.40/1.00\n",
      "Epoch [2/500]  AvgTraining Loss: 0.0197\t\tEpoch [2/500]  AvgValidation Loss: 0.0162\tValidation loss improved.\n",
      "\n",
      "0.35/1.00\n",
      "Epoch [3/500]  AvgTraining Loss: 0.0161\t\tEpoch [3/500]  AvgValidation Loss: 0.0173\t\n",
      "\n",
      "0.46/1.00\n",
      "Epoch [4/500]  AvgTraining Loss: 0.0157\t\tEpoch [4/500]  AvgValidation Loss: 0.0147\tValidation loss improved.\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [5/500]  AvgTraining Loss: 0.0143\t\tEpoch [5/500]  AvgValidation Loss: 0.0133\tValidation loss improved.\n",
      "\n",
      "0.44/1.00\n",
      "Epoch [6/500]  AvgTraining Loss: 0.0138\t\tEpoch [6/500]  AvgValidation Loss: 0.0136\t\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [7/500]  AvgTraining Loss: 0.0138\t\tEpoch [7/500]  AvgValidation Loss: 0.0124\tValidation loss improved.\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [8/500]  AvgTraining Loss: 0.0132\t\tEpoch [8/500]  AvgValidation Loss: 0.0124\tValidation loss improved.\n",
      "\n",
      "0.48/1.00\n",
      "Epoch [9/500]  AvgTraining Loss: 0.0127\t\tEpoch [9/500]  AvgValidation Loss: 0.0122\tValidation loss improved.\n",
      "\n",
      "0.48/1.00\n",
      "Epoch [10/500]  AvgTraining Loss: 0.0129\t\tEpoch [10/500]  AvgValidation Loss: 0.0124\t\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [11/500]  AvgTraining Loss: 0.0124\t\tEpoch [11/500]  AvgValidation Loss: 0.0117\tValidation loss improved.\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [12/500]  AvgTraining Loss: 0.0120\t\tEpoch [12/500]  AvgValidation Loss: 0.0113\tValidation loss improved.\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [13/500]  AvgTraining Loss: 0.0115\t\tEpoch [13/500]  AvgValidation Loss: 0.0107\tValidation loss improved.\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [14/500]  AvgTraining Loss: 0.0115\t\tEpoch [14/500]  AvgValidation Loss: 0.0104\tValidation loss improved.\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [16/500]  AvgTraining Loss: 0.0111\t\tEpoch [16/500]  AvgValidation Loss: 0.0101\tValidation loss improved.\n",
      "\n",
      "0.47/1.00\n",
      "Epoch [17/500]  AvgTraining Loss: 0.0107\t\tEpoch [17/500]  AvgValidation Loss: 0.0099\tValidation loss improved.\n",
      "\n",
      "0.48/1.00\n",
      "Epoch [18/500]  AvgTraining Loss: 0.0107\t\tEpoch [18/500]  AvgValidation Loss: 0.0098\tValidation loss improved.\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [19/500]  AvgTraining Loss: 0.0105\t\tEpoch [19/500]  AvgValidation Loss: 0.0099\t\n",
      "\n",
      "0.45/1.00\n",
      "Epoch [20/500]  AvgTraining Loss: 0.0104\t\tEpoch [20/500]  AvgValidation Loss: 0.0098\t\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [21/500]  AvgTraining Loss: 0.0099\t\tEpoch [21/500]  AvgValidation Loss: 0.0087\tValidation loss improved.\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [22/500]  AvgTraining Loss: 0.0096\t\tEpoch [22/500]  AvgValidation Loss: 0.0088\t\n",
      "\n",
      "0.48/1.00\n",
      "Epoch [23/500]  AvgTraining Loss: 0.0095\t\tEpoch [23/500]  AvgValidation Loss: 0.0093\t\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [24/500]  AvgTraining Loss: 0.0094\t\tEpoch [24/500]  AvgValidation Loss: 0.0089\t\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [25/500]  AvgTraining Loss: 0.0090\t\tEpoch [25/500]  AvgValidation Loss: 0.0078\tValidation loss improved.\n",
      "\n",
      "0.41/1.00\n",
      "Epoch [26/500]  AvgTraining Loss: 0.0089\t\tEpoch [26/500]  AvgValidation Loss: 0.0094\t\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [27/500]  AvgTraining Loss: 0.0093\t\tEpoch [27/500]  AvgValidation Loss: 0.0075\tValidation loss improved.\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [28/500]  AvgTraining Loss: 0.0083\t\tEpoch [28/500]  AvgValidation Loss: 0.0073\tValidation loss improved.\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [29/500]  AvgTraining Loss: 0.0081\t\tEpoch [29/500]  AvgValidation Loss: 0.0076\t\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [30/500]  AvgTraining Loss: 0.0077\t\tEpoch [30/500]  AvgValidation Loss: 0.0074\t\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [31/500]  AvgTraining Loss: 0.0078\t\tEpoch [31/500]  AvgValidation Loss: 0.0067\tValidation loss improved.\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [32/500]  AvgTraining Loss: 0.0076\t\tEpoch [32/500]  AvgValidation Loss: 0.0067\tValidation loss improved.\n",
      "\n",
      "0.46/1.00\n",
      "Epoch [33/500]  AvgTraining Loss: 0.0076\t\tEpoch [33/500]  AvgValidation Loss: 0.0067\t\n",
      "\n",
      "0.50/1.00\n",
      "Epoch [34/500]  AvgTraining Loss: 0.0076\t\tEpoch [34/500]  AvgValidation Loss: 0.0066\tValidation loss improved.\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [35/500]  AvgTraining Loss: 0.0069\t\tEpoch [35/500]  AvgValidation Loss: 0.0062\tValidation loss improved.\n",
      "\n",
      "0.47/1.00\n",
      "Epoch [36/500]  AvgTraining Loss: 0.0070\t\tEpoch [36/500]  AvgValidation Loss: 0.0073\t\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [37/500]  AvgTraining Loss: 0.0069\t\tEpoch [37/500]  AvgValidation Loss: 0.0058\tValidation loss improved.\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [38/500]  AvgTraining Loss: 0.0065\t\tEpoch [38/500]  AvgValidation Loss: 0.0058\tValidation loss improved.\n",
      "\n",
      "0.44/1.00\n",
      "Epoch [39/500]  AvgTraining Loss: 0.0064\t\tEpoch [39/500]  AvgValidation Loss: 0.0070\t\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [40/500]  AvgTraining Loss: 0.0063\t\tEpoch [40/500]  AvgValidation Loss: 0.0057\tValidation loss improved.\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [41/500]  AvgTraining Loss: 0.0062\t\tEpoch [41/500]  AvgValidation Loss: 0.0056\tValidation loss improved.\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [42/500]  AvgTraining Loss: 0.0058\t\tEpoch [42/500]  AvgValidation Loss: 0.0049\tValidation loss improved.\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [44/500]  AvgTraining Loss: 0.0056\t\tEpoch [44/500]  AvgValidation Loss: 0.0049\t\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [45/500]  AvgTraining Loss: 0.0053\t\tEpoch [45/500]  AvgValidation Loss: 0.0047\tValidation loss improved.\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [46/500]  AvgTraining Loss: 0.0056\t\tEpoch [46/500]  AvgValidation Loss: 0.0048\t\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [47/500]  AvgTraining Loss: 0.0053\t\tEpoch [47/500]  AvgValidation Loss: 0.0045\tValidation loss improved.\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [48/500]  AvgTraining Loss: 0.0053\t\tEpoch [48/500]  AvgValidation Loss: 0.0044\tValidation loss improved.\n",
      "\n",
      "0.46/1.00\n",
      "Epoch [49/500]  AvgTraining Loss: 0.0052\t\tEpoch [49/500]  AvgValidation Loss: 0.0048\t\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [50/500]  AvgTraining Loss: 0.0052\t\tEpoch [50/500]  AvgValidation Loss: 0.0043\tValidation loss improved.\n",
      "\n",
      "0.51/1.00\n",
      "Epoch [51/500]  AvgTraining Loss: 0.0048\t\tEpoch [51/500]  AvgValidation Loss: 0.0043\t\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [52/500]  AvgTraining Loss: 0.0048\t\tEpoch [52/500]  AvgValidation Loss: 0.0038\tValidation loss improved.\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [53/500]  AvgTraining Loss: 0.0045\t\tEpoch [53/500]  AvgValidation Loss: 0.0040\t\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [54/500]  AvgTraining Loss: 0.0044\t\tEpoch [54/500]  AvgValidation Loss: 0.0035\tValidation loss improved.\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [55/500]  AvgTraining Loss: 0.0045\t\tEpoch [55/500]  AvgValidation Loss: 0.0037\t\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [56/500]  AvgTraining Loss: 0.0044\t\tEpoch [56/500]  AvgValidation Loss: 0.0038\t\n",
      "\n",
      "0.47/1.00\n",
      "Epoch [57/500]  AvgTraining Loss: 0.0042\t\tEpoch [57/500]  AvgValidation Loss: 0.0043\t\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [58/500]  AvgTraining Loss: 0.0048\t\tEpoch [58/500]  AvgValidation Loss: 0.0038\t\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [59/500]  AvgTraining Loss: 0.0043\t\tEpoch [59/500]  AvgValidation Loss: 0.0037\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [60/500]  AvgTraining Loss: 0.0040\t\tEpoch [60/500]  AvgValidation Loss: 0.0032\tValidation loss improved.\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [61/500]  AvgTraining Loss: 0.0039\t\tEpoch [61/500]  AvgValidation Loss: 0.0032\tValidation loss improved.\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [62/500]  AvgTraining Loss: 0.0039\t\tEpoch [62/500]  AvgValidation Loss: 0.0033\t\n",
      "\n",
      "0.48/1.00\n",
      "Epoch [63/500]  AvgTraining Loss: 0.0041\t\tEpoch [63/500]  AvgValidation Loss: 0.0038\t\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [64/500]  AvgTraining Loss: 0.0039\t\tEpoch [64/500]  AvgValidation Loss: 0.0030\tValidation loss improved.\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [65/500]  AvgTraining Loss: 0.0038\t\tEpoch [65/500]  AvgValidation Loss: 0.0030\t\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [66/500]  AvgTraining Loss: 0.0038\t\tEpoch [66/500]  AvgValidation Loss: 0.0035\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [67/500]  AvgTraining Loss: 0.0038\t\tEpoch [67/500]  AvgValidation Loss: 0.0030\tValidation loss improved.\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [68/500]  AvgTraining Loss: 0.0036\t\tEpoch [68/500]  AvgValidation Loss: 0.0029\tValidation loss improved.\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [69/500]  AvgTraining Loss: 0.0038\t\tEpoch [69/500]  AvgValidation Loss: 0.0031\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [70/500]  AvgTraining Loss: 0.0037\t\tEpoch [70/500]  AvgValidation Loss: 0.0028\tValidation loss improved.\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [71/500]  AvgTraining Loss: 0.0035\t\tEpoch [71/500]  AvgValidation Loss: 0.0029\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [72/500]  AvgTraining Loss: 0.0034\t\tEpoch [72/500]  AvgValidation Loss: 0.0027\tValidation loss improved.\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [73/500]  AvgTraining Loss: 0.0038\t\tEpoch [73/500]  AvgValidation Loss: 0.0029\t\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [74/500]  AvgTraining Loss: 0.0036\t\tEpoch [74/500]  AvgValidation Loss: 0.0029\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [75/500]  AvgTraining Loss: 0.0036\t\tEpoch [75/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [76/500]  AvgTraining Loss: 0.0034\t\tEpoch [76/500]  AvgValidation Loss: 0.0032\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [77/500]  AvgTraining Loss: 0.0034\t\tEpoch [77/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [78/500]  AvgTraining Loss: 0.0034\t\tEpoch [78/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.52/1.00\n",
      "Epoch [79/500]  AvgTraining Loss: 0.0034\t\tEpoch [79/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [80/500]  AvgTraining Loss: 0.0034\t\tEpoch [80/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [81/500]  AvgTraining Loss: 0.0033\t\tEpoch [81/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [82/500]  AvgTraining Loss: 0.0034\t\tEpoch [82/500]  AvgValidation Loss: 0.0027\tValidation loss improved.\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [83/500]  AvgTraining Loss: 0.0033\t\tEpoch [83/500]  AvgValidation Loss: 0.0026\tValidation loss improved.\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [84/500]  AvgTraining Loss: 0.0033\t\tEpoch [84/500]  AvgValidation Loss: 0.0030\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [85/500]  AvgTraining Loss: 0.0034\t\tEpoch [85/500]  AvgValidation Loss: 0.0029\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [86/500]  AvgTraining Loss: 0.0034\t\tEpoch [86/500]  AvgValidation Loss: 0.0026\tValidation loss improved.\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [87/500]  AvgTraining Loss: 0.0032\t\tEpoch [87/500]  AvgValidation Loss: 0.0026\tValidation loss improved.\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [88/500]  AvgTraining Loss: 0.0033\t\tEpoch [88/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [89/500]  AvgTraining Loss: 0.0033\t\tEpoch [89/500]  AvgValidation Loss: 0.0026\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [90/500]  AvgTraining Loss: 0.0032\t\tEpoch [90/500]  AvgValidation Loss: 0.0026\t\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [91/500]  AvgTraining Loss: 0.0034\t\tEpoch [91/500]  AvgValidation Loss: 0.0030\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [92/500]  AvgTraining Loss: 0.0032\t\tEpoch [92/500]  AvgValidation Loss: 0.0025\tValidation loss improved.\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [93/500]  AvgTraining Loss: 0.0033\t\tEpoch [93/500]  AvgValidation Loss: 0.0026\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [94/500]  AvgTraining Loss: 0.0035\t\tEpoch [94/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [95/500]  AvgTraining Loss: 0.0032\t\tEpoch [95/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.59/1.00\n",
      "Epoch [96/500]  AvgTraining Loss: 0.0032\t\tEpoch [96/500]  AvgValidation Loss: 0.0024\tValidation loss improved.\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [97/500]  AvgTraining Loss: 0.0032\t\tEpoch [97/500]  AvgValidation Loss: 0.0034\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [98/500]  AvgTraining Loss: 0.0033\t\tEpoch [98/500]  AvgValidation Loss: 0.0026\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [99/500]  AvgTraining Loss: 0.0032\t\tEpoch [99/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [100/500]  AvgTraining Loss: 0.0032\t\tEpoch [100/500]  AvgValidation Loss: 0.0024\tValidation loss improved.\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [101/500]  AvgTraining Loss: 0.0032\t\tEpoch [101/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [102/500]  AvgTraining Loss: 0.0033\t\tEpoch [102/500]  AvgValidation Loss: 0.0026\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [103/500]  AvgTraining Loss: 0.0032\t\tEpoch [103/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [104/500]  AvgTraining Loss: 0.0031\t\tEpoch [104/500]  AvgValidation Loss: 0.0024\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [105/500]  AvgTraining Loss: 0.0032\t\tEpoch [105/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [106/500]  AvgTraining Loss: 0.0031\t\tEpoch [106/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.53/1.00\n",
      "Epoch [107/500]  AvgTraining Loss: 0.0032\t\tEpoch [107/500]  AvgValidation Loss: 0.0029\t\n",
      "\n",
      "0.55/1.00\n",
      "Epoch [108/500]  AvgTraining Loss: 0.0032\t\tEpoch [108/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [109/500]  AvgTraining Loss: 0.0034\t\tEpoch [109/500]  AvgValidation Loss: 0.0024\tValidation loss improved.\n",
      "\n",
      "0.54/1.00\n",
      "Epoch [110/500]  AvgTraining Loss: 0.0033\t\tEpoch [110/500]  AvgValidation Loss: 0.0028\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [112/500]  AvgTraining Loss: 0.0032\t\tEpoch [112/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [113/500]  AvgTraining Loss: 0.0034\t\tEpoch [113/500]  AvgValidation Loss: 0.0024\tValidation loss improved.\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [115/500]  AvgTraining Loss: 0.0032\t\tEpoch [115/500]  AvgValidation Loss: 0.0024\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [116/500]  AvgTraining Loss: 0.0031\t\tEpoch [116/500]  AvgValidation Loss: 0.0024\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [117/500]  AvgTraining Loss: 0.0031\t\tEpoch [117/500]  AvgValidation Loss: 0.0024\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [118/500]  AvgTraining Loss: 0.0031\t\tEpoch [118/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [119/500]  AvgTraining Loss: 0.0032\t\tEpoch [119/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [120/500]  AvgTraining Loss: 0.0032\t\tEpoch [120/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [121/500]  AvgTraining Loss: 0.0031\t\tEpoch [121/500]  AvgValidation Loss: 0.0024\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [122/500]  AvgTraining Loss: 0.0033\t\tEpoch [122/500]  AvgValidation Loss: 0.0024\t\n",
      "\n",
      "0.56/1.00\n",
      "Epoch [123/500]  AvgTraining Loss: 0.0032\t\tEpoch [123/500]  AvgValidation Loss: 0.0025\t\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [124/500]  AvgTraining Loss: 0.0031\t\tEpoch [124/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "0.57/1.00\n",
      "Epoch [125/500]  AvgTraining Loss: 0.0033\t\tEpoch [125/500]  AvgValidation Loss: 0.0027\t\n",
      "\n",
      "Model did not improve within the last 10 epochs. Stopping training.\n",
      "TrainedModelName: bestmodel_48_11_48_3_1_0.001, BestValAcc: 0.002399779623374343\n",
      "0.58/1.00\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_acc = 0\n",
    "best_net = None\n",
    "best_tr_loss_hist = None\n",
    "best_val_loss_hist = None\n",
    "lr = 1e-3\n",
    "for fk in [48]:\n",
    "    for sk in [48]:\n",
    "        for fksize in [11]:\n",
    "            for sksize in [3]:\n",
    "                for lastsize in [1]:\n",
    "                    try:\n",
    "                        print(fk, sk, fksize, sksize, lastsize)\n",
    "                        net = ConvNet(learning_rate=lr, first_kernel=fk, \n",
    "                                    first_kernel_size=fksize, second_kernel=sk,\n",
    "                                    second_kernel_size=sksize, \n",
    "                                    last_kernel_size=lastsize)\n",
    "                        tr_loss_hist, val_loss_hist = net.train()\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    net.load_model(net.model_name+net.pytorch_extension)\n",
    "                    predictions = net.predict()\n",
    "                    np.save(\"estimations_val.npy\", predictions)\n",
    "                    acc = main([\"estimations_val.npy\", \"valid.txt\"])\n",
    "                    scipy.misc.imsave('outfile.jpg', predictions[0])\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_net = net\n",
    "                        best_tr_loss_hist = tr_loss_hist\n",
    "                        best_val_loss_hist = val_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = net.predict()\n",
    "np.save(\"estimations_val.npy\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "scipy.misc.imsave('outfile.jpg', predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 256, 256, 3)\n",
      "0.58/1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57513961791992196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "main([\"estimations_val.npy\", \"valid.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/bestmodel_16_11_32_3_1_0.001.pt\t0.44/1.00\n",
      "\n",
      "models/bestmodel_16_11_48_3_1_0.001.pt\t0.58/1.00\n",
      "\n",
      "models/bestmodel_16_3_32_3_3_0.001.pt\t0.40/1.00\n",
      "\n",
      "models/bestmodel_16_3_32_7_1_0.001.pt\t0.32/1.00\n",
      "\n",
      "models/bestmodel_16_3_48_3_3_0.001.pt\t0.38/1.00\n",
      "\n",
      "models/bestmodel_16_3_48_7_1_0.001.pt\t0.38/1.00\n",
      "\n",
      "models/bestmodel_16_5_32_3_3_0.001.pt\t0.39/1.00\n",
      "\n",
      "models/bestmodel_16_5_32_7_1_0.001.pt\t0.42/1.00\n",
      "\n",
      "models/bestmodel_16_5_48_3_3_0.001.pt\t0.41/1.00\n",
      "\n",
      "models/bestmodel_16_5_48_7_1_0.001.pt\t0.41/1.00\n",
      "\n",
      "models/bestmodel_16_7_32_5_1_0.001.pt\t0.32/1.00\n",
      "\n",
      "models/bestmodel_16_7_48_5_1_0.001.pt\t0.47/1.00\n",
      "\n",
      "models/bestmodel_16_9_32_5_1_0.001.pt\t0.37/1.00\n",
      "\n",
      "models/bestmodel_16_9_48_5_1_0.001.pt\t0.44/1.00\n",
      "\n",
      "models/bestmodel_24_11_32_3_1_0.001.pt\t0.48/1.00\n",
      "\n",
      "models/bestmodel_24_3_32_3_3_0.001.pt\t0.40/1.00\n",
      "\n",
      "models/bestmodel_24_3_32_7_1_0.001.pt\t0.13/1.00\n",
      "\n",
      "models/bestmodel_24_3_48_3_3_0.001.pt\t0.38/1.00\n",
      "\n",
      "models/bestmodel_24_3_48_7_1_0.001.pt\t0.25/1.00\n",
      "\n",
      "models/bestmodel_24_5_32_3_3_0.001.pt\t0.38/1.00\n",
      "\n",
      "models/bestmodel_24_5_32_7_1_0.001.pt\t0.33/1.00\n",
      "\n",
      "models/bestmodel_24_7_32_5_1_0.001.pt\t0.39/1.00\n",
      "\n",
      "models/bestmodel_24_9_32_5_1_0.001.pt\t0.40/1.00\n",
      "\n",
      "models/bestmodel_36_11_36_3_1_0.001.pt\t0.46/1.00\n",
      "\n",
      "models/bestmodel_36_11_48_3_1_0.001.pt\t0.42/1.00\n",
      "\n",
      "models/bestmodel_36_3_36_7_1_0.001.pt\t0.42/1.00\n",
      "\n",
      "models/bestmodel_36_3_48_7_1_0.001.pt\t0.43/1.00\n",
      "\n",
      "models/bestmodel_36_5_36_7_1_0.001.pt\t0.42/1.00\n",
      "\n",
      "models/bestmodel_36_5_48_7_1_0.001.pt\t"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "lr = 1e-3\n",
    "for file in sorted(glob(\"models/*.pt\")):\n",
    "    print(file, end=\"\\t\")\n",
    "    model = file.split('_')[1:]\n",
    "    net = ConvNet(learning_rate=1e-3, first_kernel=int(model[0]), \n",
    "                                first_kernel_size=int(model[1]), second_kernel=int(model[2]),\n",
    "                                second_kernel_size=int(model[3]), \n",
    "                                last_kernel_size=int(model[4]))\n",
    "    net.load_model(file)\n",
    "    predictions = net.predict()\n",
    "    np.save(\"_estimations_val.npy\", predictions)\n",
    "    main([\"_estimations_val.npy\", \"valid.txt\"])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 32 0.0001\n",
      "0.59/1.00\n",
      "Epoch [1/500]  AvgTraining Loss: 215.2629\t\tEpoch [1/500]  AvgValidation Loss: 163.7536\tValidation loss improved.\n",
      "\n",
      "0.58/1.00\n",
      "Epoch [2/500]  AvgTraining Loss: 199.3505\t\tEpoch [2/500]  AvgValidation Loss: 156.6321\tValidation loss improved.\n",
      "\n",
      "0.60/1.00\n",
      "Epoch [3/500]  AvgTraining Loss: 193.3036\t\tEpoch [3/500]  AvgValidation Loss: 158.7631\t\n",
      "\n",
      "0.60/1.00\n",
      "Epoch [4/500]  AvgTraining Loss: 187.9430\t\tEpoch [4/500]  AvgValidation Loss: 154.8862\tValidation loss improved.\n",
      "\n",
      "0.60/1.00\n",
      "Epoch [5/500]  AvgTraining Loss: 186.3637\t\tEpoch [5/500]  AvgValidation Loss: 155.5980\t\n",
      "\n",
      "0.60/1.00\n",
      "Epoch [6/500]  AvgTraining Loss: 185.8454\t\tEpoch [6/500]  AvgValidation Loss: 152.1695\tValidation loss improved.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f8a75fbbc1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtr_loss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_extension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/483/hw3/network.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, early_stop_epochs, verbose)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         optimizer = torch.optim.RMSprop(self.net.parameters(), lr=self.learning_rate,\n\u001b[1;32m    148\u001b[0m                                        weight_decay=self.reg, momentum=0.9)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/483/hw3/network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# yatiyommm\n",
    "# learning rate dusurup tekrar dene\n",
    "\n",
    "best_acc = 0\n",
    "best_net = None\n",
    "best_tr_loss_hist = None\n",
    "best_val_loss_hist = None\n",
    "# lrs = np.random.uniform(1e-7, 1e-1, 3)\n",
    "# lrs = [1e-2, 1e-4, 1e-6]\n",
    "lrs = [1e-3]\n",
    "# bss = [32, 64, 128]\n",
    "bss = [32]\n",
    "# regs = np.random.uniform(1e-7, 1e-1, 3)\n",
    "# regs = [1e-1, 1e-3, 1e-6]\n",
    "regs = [1e-4]\n",
    "for lr in lrs:\n",
    "    for bs in bss:\n",
    "        for reg in regs:\n",
    "            print(lr, bs, reg)\n",
    "            net = ConvNet(learning_rate=lr, batch_size=bs, reg=reg)\n",
    "            tr_loss_hist, val_loss_hist = net.train()\n",
    "\n",
    "            net.load_model(net.model_name+net.pytorch_extension)\n",
    "            predictions = net.predict()\n",
    "            np.save(\"estimations_val.npy\", predictions)\n",
    "            acc = main([\"estimations_val.npy\", \"valid.txt\"])\n",
    "            scipy.misc.imsave('outfile.jpg', predictions[0])\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_net = net\n",
    "                best_tr_loss_hist = tr_loss_hist\n",
    "                best_val_loss_hist = val_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet(learning_rate=1e-3, batch_size=32, reg=1e-4)\n",
    "net.load_model(\"bestmodel_0.001_32_0.01__613.pt\")\n",
    "predictions = net.predict(test=True)\n",
    "print(predictions.shape)\n",
    "np.save(\"estimations_test.npy\", predictions)\n",
    "\n",
    "# plt.plot(best_tr_loss_hist, label=\"train loss\")\n",
    "# plt.plot(best_val_loss_hist, label=\"validation loss\")\n",
    "# plt.legend()\n",
    "# plt.savefig(\"plot.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_model(\"bestmodel_0.001_32_0.0001.pt\")\n",
    "np.save(\"estimations_val.npy\", net.predict())\n",
    "\n",
    "main([\"estimations_val.npy\", \"valid.txt\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
