{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Network for Regression (Estimate blood pressure from PPG signal)\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [HW page](http://kovan.ceng.metu.edu.tr/~sinan/DL/index.html) on the course website.*\n",
    "\n",
    "Having gained some experience with neural networks, let us train a network that estimates the blood pressure from a PPG signal window.\n",
    "\n",
    "All of your work for this exercise will be done in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Photoplethysmograph (PPG) signal\n",
    "\n",
    "A PPG (photoplethysmograph) signal is a signal obtained with a pulse oximeter, which illuminates the skin and measures changes in light absorption. A PPG signal carries rich information about the status of the cardiovascular health of a person, such as breadth rate, heart rate and blood pressure. An example is shown below, where you also see the blood pressure signal that we will estimate (the data also has the ECG signal, which you should ignore).\n",
    "\n",
    "<img width=\"80%\" src=\"PPG_ABG_ECG_example.png\">\n",
    "\n",
    "\n",
    "# Constructing the Dataset \n",
    "\n",
    "In this task, you are expected to perform the full pipeline for creating a learning system from scratch. Here is how you should construct the dataset:\n",
    "* Download the dataset from the following website, and only take \"Part 1\" from it (it is too big): https://archive.ics.uci.edu/ml/datasets/Cuff-Less+Blood+Pressure+Estimation\n",
    "* Take a window of size $W$ from the PPG channel between time $t$ and $t+W$. Let us call this $\\textbf{x}_t$.\n",
    "* Take the corresponding window of size $W$ from the ABP (arterial blood pressure) channel between time $t$ and $t+W$. Find the maxima and minima of this signal within the window (you can use \"findpeaks\" from Matlab or \"find_peaks_cwt\" from scipy). Here is an example window from the ABP signal, and its peaks:\n",
    " <img width=\"60%\" src=\"ABP_peaks.png\">\n",
    "    \n",
    "* Calculate the average of the maxima, call it $y^1_t$, and the average of the minima, call it $y^2_t$.\n",
    "* Slide the window over the PPG signals and collect many $(\\textbf{x}_t, <y^1_t, y^2_t>)$ instances. In other words, your network outputs two values.\n",
    "* This will be your input-output for training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ertugrulcan46/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from metu.data_utils import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "from cs231n.classifiers.neural_net_for_regression import TwoLayerNet\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "  np.random.seed(0)\n",
    "  return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "  np.random.seed(1)\n",
    "  X = 10 * np.random.randn(num_inputs, input_size)\n",
    "  y = np.array([[0, 1, 2], [1, 2, 3], [2, 3, 4], [2, 1, 4], [2, 1, 4]])\n",
    "  return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute scores\n",
    "Open the file `cs231n/classifiers/neural_net_for_regression.py` and look at the method `TwoLayerNet.loss`. This function is very similar to the loss functions you have written for the previous exercises: It takes the data and weights and computes the *regression* scores, the squared error loss, and the gradients on the parameters. \n",
    "\n",
    "To be more specific, you will implement the following loss function:\n",
    "\n",
    "$$\\frac{1}{2}\\sum_i\\sum_{j} (o_{ij} - y_{ij})^2 + \\frac{1}{2}\\lambda\\sum_j w_j^2,$$\n",
    "\n",
    "where $i$ runs through the samples in the batch; $o_{ij}$ is the prediction of the network for the $i^{th}$ sample for output $j$, and $y_{ij}$ is the correct value; $\\lambda$ is the weight of the regularization term.\n",
    "\n",
    "The first layer uses ReLU as the activation function. The output layer does not use any activation functions.\n",
    "\n",
    "Implement the first part of the forward pass which uses the weights and biases to compute the scores for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "correct scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Difference between your scores and correct scores:\n",
      "3.6802720745909845e-08\n"
     ]
    }
   ],
   "source": [
    "scores = net.loss(X)\n",
    "print 'Your scores:'\n",
    "print scores\n",
    "print\n",
    "print 'correct scores:'\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print correct_scores\n",
    "print\n",
    "\n",
    "# The difference should be very small. We get < 1e-7\n",
    "print 'Difference between your scores and correct scores:'\n",
    "print np.sum(np.abs(scores - correct_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute loss\n",
    "In the same function, implement the second part that computes the data and regularizaion loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between your loss and correct loss:\n",
      "2.5480062504357193e-11\n"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 66.3406756909\n",
    "\n",
    "# should be very small, we get < 1e-10\n",
    "print 'Difference between your loss and correct loss:'\n",
    "print np.sum(np.abs(loss - correct_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "Implement the rest of the function. This will compute the gradient of the loss with respect to the variables `W1`, `b1`, `W2`, and `b2`. Now that you (hopefully!) have a correctly implemented forward pass, you can debug your backward pass using a numeric gradient check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 5.463838e-04\n",
      "W2 max relative error: 3.755046e-04\n",
      "b2 max relative error: 1.443387e-06\n",
      "b1 max relative error: 2.188996e-07\n"
     ]
    }
   ],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "  f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "  param_grad_num = eval_numerical_gradient(f, net.params[param_name])\n",
    "  print '%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the PPG dataset for training your regression network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3000 , (71000, 3)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Number of instances in the training set:  8999\n",
      "Number of instances in the validation set:  400\n",
      "Number of instances in the testing set:  600\n"
     ]
    }
   ],
   "source": [
    "# Load the PPG dataset\n",
    "# If your memory turns out to be sufficient, try loading a subset\n",
    "def get_data(datafile, training_ratio=0.9, test_ratio=0.06, val_ratio=0.04):\n",
    "  # Load the PPG training data \n",
    "  X, y = load_dataset(datafile, input_size)\n",
    "  # TODO: Split the data into training, validation and test sets\n",
    "  length=len(y)\n",
    "  num_training=int(length*training_ratio)\n",
    "  num_val = int(length*val_ratio)\n",
    "  num_test = min((length-num_training-num_val), int(length*test_ratio))\n",
    "  mask = range(num_training-1)\n",
    "  X_train = X[mask]\n",
    "  y_train = y[mask]\n",
    "  mask = range(num_training, num_training+num_test)\n",
    "  X_test = X[mask]\n",
    "  y_test = y[mask]\n",
    "  mask = range(num_training+num_test, num_training+num_test+num_val)\n",
    "  X_val = X[mask]\n",
    "  y_val = y[mask]\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "datafile = 'metu/dataset/part1.mat' #TODO: PATH to your data file\n",
    "input_size = 1000 # TODO: Size of the input of the network\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_data(datafile)\n",
    "print \"Number of instances in the training set: \", len(X_train)\n",
    "print \"Number of instances in the validation set: \", len(X_val)\n",
    "print \"Number of instances in the testing set: \", len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now train our network on the PPG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8999, 1000) (8999, 2)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\n",
      "[64]\n",
      "[6e-05]\n",
      "Hidden: 600\n",
      "Batch: 64\n",
      "LR: 6e-05\n",
      "iteration 0 / 5000: loss 927222.181899\n",
      "iteration 100 / 5000: loss 17465478643731.658203\n",
      "iteration 200 / 5000: loss 17369092109604.162109\n",
      "iteration 300 / 5000: loss 17276162983121.414062\n",
      "iteration 400 / 5000: loss 17187508745329.957031\n",
      "iteration 500 / 5000: loss 17102788587131.337891\n",
      "iteration 600 / 5000: loss 17021029348796.560547\n",
      "iteration 700 / 5000: loss 16942187155426.419922\n",
      "iteration 800 / 5000: loss 16867586712321.830078\n",
      "iteration 900 / 5000: loss 16795539210369.515625\n",
      "iteration 1000 / 5000: loss 16725977589602.710938\n",
      "iteration 1100 / 5000: loss 16659531015331.101562\n",
      "iteration 1200 / 5000: loss 16595957701011.562500\n",
      "iteration 1300 / 5000: loss 16534537248049.234375\n",
      "iteration 1400 / 5000: loss 16475244230708.193359\n",
      "iteration 1500 / 5000: loss 16419083359750.570312\n",
      "iteration 1600 / 5000: loss 16364790838203.111328\n",
      "iteration 1700 / 5000: loss 16312321470417.328125\n",
      "iteration 1800 / 5000: loss 16262155570662.654297\n",
      "iteration 1900 / 5000: loss 16214116501910.017578\n",
      "iteration 2000 / 5000: loss 16167664665150.097656\n",
      "iteration 2100 / 5000: loss 16122784734866.613281\n",
      "iteration 2200 / 5000: loss 16080241866389.857422\n",
      "iteration 2300 / 5000: loss 16039082996857.757812\n",
      "iteration 2400 / 5000: loss 15999276883338.339844\n",
      "iteration 2500 / 5000: loss 15961191207333.910156\n",
      "iteration 2600 / 5000: loss 15924695287419.960938\n",
      "iteration 2700 / 5000: loss 15889381937526.773438\n",
      "iteration 2800 / 5000: loss 15855241764819.572266\n",
      "iteration 2900 / 5000: loss 15822859539055.490234\n",
      "iteration 3000 / 5000: loss 15791512315956.384766\n",
      "iteration 3100 / 5000: loss 15761178056127.316406\n",
      "iteration 3200 / 5000: loss 15732138868917.580078\n",
      "iteration 3300 / 5000: loss 15704297110547.060547\n",
      "iteration 3400 / 5000: loss 15677343758264.542969\n",
      "iteration 3500 / 5000: loss 15651272960826.248047\n",
      "iteration 3600 / 5000: loss 15626532862911.625000\n",
      "iteration 3700 / 5000: loss 15602572595636.978516\n",
      "iteration 3800 / 5000: loss 15579376340973.531250\n",
      "iteration 3900 / 5000: loss 15557160948362.980469\n",
      "iteration 4000 / 5000: loss 15535852893165.773438\n",
      "iteration 4100 / 5000: loss 15515216616111.033203\n",
      "iteration 4200 / 5000: loss 15495248410993.115234\n",
      "iteration 4300 / 5000: loss 15476292457995.988281\n",
      "iteration 4400 / 5000: loss 15457927541144.191406\n",
      "iteration 4500 / 5000: loss 15440142140480.957031\n",
      "iteration 4600 / 5000: loss 15423103184731.000000\n",
      "iteration 4700 / 5000: loss 15406754973729.011719\n",
      "iteration 4800 / 5000: loss 15390917335934.330078\n",
      "iteration 4900 / 5000: loss 15375587883086.902344\n",
      "Validation error:  13.35158893279525 \n",
      "\n",
      "Validation error:  13.35158893279525\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train a neural network\n",
    "\n",
    "input_size = input_size\n",
    "hidden_size = 500 # TODO: Choose a suitable hidden layer size\n",
    "hidden_sizes = np.random.uniform(100, 800, 10)\n",
    "batch_sizes = np.linspace(8, 1024, 10)\n",
    "learning_rates = np.random.uniform(5e-8, 5e-7, 10)\n",
    "hidden_sizes = np.linspace(100, 1000, 5)\n",
    "batch_sizes = np.linspace(32, 1024, 5)\n",
    "learning_rates = np.linspace(1e-8, 5e-7, 5)\n",
    "hidden_sizes = np.linspace(300, 1000, 5)\n",
    "batch_sizes = np.linspace(32, 128, 2)\n",
    "learning_rates = np.linspace(4e-7, 8e-7, 5)\n",
    "hidden_sizes = [400, 600, 800]\n",
    "batch_sizes = [32, 64]\n",
    "learning_rates = np.linspace(5e-6, 6e-5, 5)\n",
    "hidden_sizes = [600]\n",
    "batch_sizes = [64]\n",
    "learning_rates = [6e-05]\n",
    "print hidden_sizes\n",
    "print batch_sizes\n",
    "print learning_rates\n",
    "num_classes = 2 # We have two outputs\n",
    "# Train the network\n",
    "for h in hidden_sizes:\n",
    "    h = int(h)\n",
    "    for b in batch_sizes:\n",
    "        b = int(b)\n",
    "        for l in learning_rates:\n",
    "            net = TwoLayerNet(input_size, h, num_classes)\n",
    "            print \"Hidden: {}\\nBatch: {}\\nLR: {}\".format(str(h), str(b), str(l))\n",
    "            stats = net.train(X_train, y_train, X_val, y_val,\n",
    "                        num_iters=5000, batch_size=b,\n",
    "                        learning_rate=l, learning_rate_decay=0.95,\n",
    "                        reg=0.5, verbose=True)\n",
    "            val_err = np.sum(np.square(net.predict(X_val) - y_val), axis=1).mean()\n",
    "            print 'Validation error: ', val_err, '\\n'\n",
    "\n",
    "# Predict on the validation set\n",
    "#val_err = ... # TODO: Perform prediction on the validation set\n",
    "val_err = np.sum(np.square(net.predict(X_val) - y_val), axis=1).mean()\n",
    "print 'Validation error: ', val_err\n",
    "\n",
    "# iteration 4900 / 5000: loss 15697.752875\n",
    "# Validation error:  18.890347955\n",
    "\n",
    "#####################################################\n",
    "# For randomly selected 10k datapoints,             #\n",
    "# the best performing network that I could found is;#\n",
    "# ValErr: 12.33443476524403                         #\n",
    "# Hidden: 600                                       #\n",
    "# Batch: 32                                         #\n",
    "# LR: 6e-05                                     #\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error:  9.961596983403263 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_err = np.sum(np.square(net.predict(X_test) - y_test), axis=1).mean()\n",
    "print 'Test error: ', val_err, '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the training and improve learning\n",
    "You should be able to get a validation error of 5.\n",
    "\n",
    "So far so good. But, is it really good? Let us plot the validation and training errors to see how good the network did. Did it memorize or generalize? Discuss your observations and conclusions. If its performance is not looking good, propose and test measures. This is the part that will show me how well you have digested everything covered in the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45a9723750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and train / validation errors\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "train = plt.plot(stats['train_err_history'], label='train')\n",
    "val = plt.plot(stats['val_err_history'], label='val')\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.title('Classification error history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning and Improving Your Network (Bonus)\n",
    "There are many aspects and hyper-parameters you can play with. Do play with them and find the best setting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
